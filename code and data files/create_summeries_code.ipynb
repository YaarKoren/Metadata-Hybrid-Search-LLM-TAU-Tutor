{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 51286,
     "status": "ok",
     "timestamp": 1735395021237,
     "user": {
      "displayName": "Orpaz Ashkenazy",
      "userId": "18114821235404041069"
     },
     "user_tz": -120
    },
    "id": "csp-2q6_dMvF",
    "outputId": "95c53f97-8359-4738-fe05-1b1b4a64f1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m850.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
      "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U langchain-text-splitters langchain-community langgraph langchain-openai langchain-chroma pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f34gRGFdRIf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # insert key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K9E6NbNkkTS"
   },
   "source": [
    "## Load the data to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1735395021240,
     "user": {
      "displayName": "Orpaz Ashkenazy",
      "userId": "18114821235404041069"
     },
     "user_tz": -120
    },
    "id": "1J8hQiGFjfi-",
    "outputId": "34a7a1c8-daa8-454b-d786-e3113acf5c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/hardware_materials.zip\n",
      "   creating: materials/\n",
      "  inflating: materials/.DS_Store     \n",
      "   creating: materials/subtitles/\n",
      "  inflating: materials/subtitles/.DS_Store  \n",
      "  inflating: materials/subtitles/lecture_10_en.srt  \n",
      "  inflating: materials/subtitles/lecture_11a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_11b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_12a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_12b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_1a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_1b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_2a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_2b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_3a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_3b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_4a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_4b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_5a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_5b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_6a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_6b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_7a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_7b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_8a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_8b_en.srt  \n",
      "  inflating: materials/subtitles/lecture_9a_en.srt  \n",
      "  inflating: materials/subtitles/lecture_9b_en.srt  \n",
      "  inflating: materials/subtitles/srt_to_link.json  \n",
      "   creating: materials/texts/\n",
      "  inflating: materials/texts/.DS_Store  \n",
      "  inflating: materials/texts/lecture_10_en.txt  \n",
      "  inflating: materials/texts/lecture_11a_en.txt  \n",
      "  inflating: materials/texts/lecture_11b_en.txt  \n",
      "  inflating: materials/texts/lecture_12a_en.txt  \n",
      "  inflating: materials/texts/lecture_12b_en.txt  \n",
      "  inflating: materials/texts/lecture_1a_en.txt  \n",
      "  inflating: materials/texts/lecture_1b_en.txt  \n",
      "  inflating: materials/texts/lecture_2a_en.txt  \n",
      "  inflating: materials/texts/lecture_2b_en.txt  \n",
      "  inflating: materials/texts/lecture_3a_en.txt  \n",
      "  inflating: materials/texts/lecture_3b_en.txt  \n",
      "  inflating: materials/texts/lecture_4a_en.txt  \n",
      "  inflating: materials/texts/lecture_4b_en.txt  \n",
      "  inflating: materials/texts/lecture_5a_en.txt  \n",
      "  inflating: materials/texts/lecture_5b_en.txt  \n",
      "  inflating: materials/texts/lecture_6a_en.txt  \n",
      "  inflating: materials/texts/lecture_6b_en.txt  \n",
      "  inflating: materials/texts/lecture_7a_en.txt  \n",
      "  inflating: materials/texts/lecture_7b_en.txt  \n",
      "  inflating: materials/texts/lecture_8a_en.txt  \n",
      "  inflating: materials/texts/lecture_8b_en.txt  \n",
      "  inflating: materials/texts/lecture_9a_en.txt  \n",
      "  inflating: materials/texts/lecture_9b_en.txt  \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/materials/\n",
      "  inflating: __MACOSX/materials/._.DS_Store  \n",
      "   creating: __MACOSX/materials/subtitles/\n",
      "  inflating: __MACOSX/materials/subtitles/._.DS_Store  \n",
      "   creating: __MACOSX/materials/texts/\n",
      "  inflating: __MACOSX/materials/texts/._.DS_Store  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_10_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_11a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_11b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_12a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_12b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_1a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_1b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_2a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_2b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_3a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_3b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_4a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_4b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_5a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_5b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_6a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_6b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_7a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_7b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_8a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_8b_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_9a_en.txt  \n",
      "  inflating: __MACOSX/materials/texts/._lecture_9b_en.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/hardware_materials.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eni0g85I6Sqe"
   },
   "source": [
    "## Creating summeries for each lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281857,
     "status": "ok",
     "timestamp": 1734531769089,
     "user": {
      "displayName": "Orpaz Ashkenazy",
      "userId": "18114821235404041069"
     },
     "user_tz": -120
    },
    "id": "bPyMUL8evvKv",
    "outputId": "66b03c27-b04d-4b71-ce7d-726e54bebcbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished to summerize lecture number 4.\n",
      "Finished to summerize lecture number 8.\n",
      "Finished to summerize lecture number 11.\n",
      "Finished to summerize lecture number 3.\n",
      "Finished to summerize lecture number 7.\n",
      "Finished to summerize lecture number 6.\n",
      "Finished to summerize lecture number 9.\n",
      "Finished to summerize lecture number 2.\n",
      "Finished to summerize lecture number 5.\n",
      "Finished to summerize lecture number 1.\n",
      "Finished to summerize lecture number 10.\n",
      "Finished to summerize lecture number 12.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "PATH_TO_SUMMARIES  = '/content/materials/summaries/'\n",
    "PATH_TO_TEXTS = '/content/materials/texts'\n",
    "\n",
    "# read file content and return it\n",
    "def load_file_content(file_name: str):\n",
    "    try:\n",
    "        with open(os.path.join(PATH_TO_TEXTS, file_name), \"r\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_name} was not found.\")\n",
    "        return None\n",
    "\n",
    "# generate summary for given content\n",
    "def create_summary_content(content: str, lecture_number: int, model: ChatOpenAI):\n",
    "    prompt = (\n",
    "        \"Act as a teacher who is a professional summarizer and expert in hardware. Write a detailed, comprehensive, structured and easy-to-understand summary of the provided content.\\n\"\n",
    "        f\"The title should include 'Summary of Lecture {lecture_number}'.\\n\"\n",
    "        \"Start with a brief overview that explains the main purpose and structure of the lecture in simple terms.\\n\"\n",
    "        \"Organize the summary into clear sections and with well-structured paragraphs and bullet points based on the main topics discussed.\\n\"\n",
    "        \"For each section:\\n\"\n",
    "        \"1. Elaborate thoroughly on explaining the key concepts, themes, or methodologies. \"\n",
    "        \"For each subject, explain the subject in depth, including definition and explanation.\\n\"\n",
    "        \"2. Include specific and concrete example for every key concept.\\n\"\n",
    "        \"3. Highlight connections between different topics discussed, especially where they build upon each other or showcase cause-and-effect relationships.\\n\"\n",
    "        \"Make the language professional, concise, and tailored to explain the material clearly to students.\\n\"\n",
    "        \"Rely strictly on the provided text, without including external information.\\n\"\n",
    "        \"The goal is to provide a summary that is accurate, easy to follow, and helps students quickly understand and review the material, without omitting any important information.\\n\"\n",
    "        f\"Content to summarize:\\n\\n{content}\\n\"\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def add_summeries_files(text_files: list, to_create_summeries: bool):\n",
    "  summary_files = []\n",
    "  os.makedirs(PATH_TO_SUMMARIES, exist_ok=True)\n",
    "\n",
    "  # if summeries files are already exists - only add them to the list and return it (the list)\n",
    "  if not to_create_summeries:\n",
    "    summary_files = [f for f in os.listdir(PATH_TO_SUMMARIES) if f.endswith('.txt')]\n",
    "    # check if there are really files there, and return the list\n",
    "    if len(summary_files) > 0:\n",
    "      print(f\"The existing files names were added to the list\")\n",
    "    else:\n",
    "      print(f\"Did not found existing summary files in {PATH_TO_SUMMARIES}!!\")\n",
    "    return summary_files\n",
    "\n",
    "  # clear old files from the folder (if they exists)\n",
    "  for filename in os.listdir(PATH_TO_SUMMARIES):\n",
    "    file_path = os.path.join(PATH_TO_SUMMARIES, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "      os.remove(file_path)\n",
    "\n",
    "  # create dict of number of lecture and its files\n",
    "  lectures_dict = {}\n",
    "  pattern = re.compile(r\"lecture_(\\d+)[a-z]*_en.txt\")\n",
    "  for file in text_files:\n",
    "    match = pattern.search(file)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        if number in lectures_dict:\n",
    "          lectures_dict[number].append(file)\n",
    "        else:\n",
    "          lectures_dict[number] = [file]\n",
    "\n",
    "  # create LLM object\n",
    "  summerized_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "  # for every lecture:\n",
    "  for lecture_num in lectures_dict:\n",
    "    # 1. read the files and create one combined content\n",
    "    lectures_dict[lecture_num].sort()\n",
    "    lecture_content = \"\"\n",
    "    for file_name in lectures_dict[lecture_num]:\n",
    "      file_content = load_file_content(file_name)\n",
    "      if file_content is not None:\n",
    "        lecture_content += file_content + \"\\n\"\n",
    "\n",
    "    if lecture_content != \"\":\n",
    "      # 2. create summary of the content using the llm\n",
    "      summary_content = create_summary_content(lecture_content, lecture_num, summerized_llm)\n",
    "\n",
    "      # 3. put the summary into a file\n",
    "      summary_file_name = f\"Summary_of_lecture_{lecture_num}_en.txt\"\n",
    "      with open(os.path.join(PATH_TO_SUMMARIES, summary_file_name), \"w\") as file:\n",
    "        file.write(summary_content)\n",
    "\n",
    "      # 4. enter the file name to text_files\n",
    "      summary_files.append(summary_file_name)\n",
    "\n",
    "    print(f\"Finished to summerize lecture number {lecture_num}.\")\n",
    "\n",
    "  return summary_files\n",
    "\n",
    "text_files = [f for f in os.listdir(PATH_TO_TEXTS) if f.endswith('.txt')]\n",
    "summary_files = add_summeries_files(text_files, to_create_summeries = True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1iUjduPN4owA2l2kN8Z_8siMkokegk9eo",
     "timestamp": 1733498625479
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
